# 多國語系介紹台灣-聊天機器人🇹🇼✨

這是一個基於 Chainlit 和 LangChain 的智能聊天機器人應用程式，專門介紹台灣的美食、文化和地標，並提供即時翻譯功能。🤖💬

## 📖 專案介紹

本專案整合了兩個 AI 模型：

- **LLaMA 3.1 模型** 🦙：擔任台灣導遊專家，提供台灣各地美食、文化和地標的專業建議
- **TranslateGemma 模型** 🌐：將導遊的回應從繁體中文翻譯成英文

使用者可以詢問任何關於台灣的問題，系統會以條列式的方式提供專業建議，並附上英文翻譯結果。✨

## ✨ 功能特色

- 🗺️ 台灣旅遊諮詢服務
- 🍜 美食推薦與介紹
- 🌐 即時中英翻譯
- 💬 互動式聊天介面
- 🔒 **完全本地運行，無使用額度限制**
- 💰 **免費使用，不需訂閱費用**

## 💻 系統需求

- **Python 版本**：3.10 或以上 🐍
- **Ollama**：需要在本地安裝並運行 Ollama
- **必要模型**：
  - `llama3.1:latest` 🦙
  - `translategemma:4b` 🌐

## ⚙️ 硬體規格參考

本專案在以下硬體配置下開發測試：

### 🖥️ 開發環境
- **MacBook Air M1 16GB** 
- **GeForce RTX 4060 8GB** 

### ⚡ 效能說明

> **⚠️ 重要：回覆速度完全取決於您的硬體配置！**

- 如果您的硬體配置**比上述規格更高級**，您可以：
  - ✅ 體驗**更快的回覆速度**
  - ✅ 嘗試**更大的模型**（如 `llama3.1:70b` 或 `translategemma:27b`）
  - ✅ 同時運行**多個模型**

- 如果您的硬體配置**較低**：
  - 建議使用較小的模型（如 `llama3.1:8b`）
  - 回覆時間可能需要更長
  - 考慮關閉其他佔用資源的應用程式

## 📦 安裝步驟

### 1. 安裝 Python 套件

使用 pip 安裝所需的套件：

```bash
pip install -r requirements.txt
```

### 2. 安裝 Ollama

前往 [Ollama 官網](https://ollama.ai/) 下載並安裝 Ollama。

### 3. 下載所需的 AI 模型

```bash
# 下載 LLaMA 3.1 模型
ollama pull llama3.1:latest

# 下載 TranslateGemma 模型
ollama pull translategemma:4b
```

## 🚀 使用方法

### 啟動應用程式

在專案目錄下執行以下指令：

```bash
chainlit run app.py
```

### 使用介面

1. 啟動後，瀏覽器會自動開啟 Chainlit 介面（通常是 `http://localhost:8000`）
2. 在聊天框中輸入您的問題，例如：
   - "推薦台北的美食"
   - "台南有什麼必去的景點？"
   - "介紹台灣的夜市文化"
3. 系統會提供繁體中文的詳細建議，並附上英文翻譯

## 📚 安裝的套件庫

| 套件名稱 | 用途 |
|---------|------|
| `chainlit` | 提供互動式聊天介面 |
| `langchain` | AI 應用程式開發框架 |
| `langchain-ollama` | 與 Ollama 模型整合 |

詳細版本請參閱 `requirements.txt`

## 📁 專案結構

```
.
├── app.py              # 主程式檔案
├── README.md           # 專案說明文件
└── requirements.txt    # Python 套件依賴列表
```

## ⚠️ 注意事項

- 確保 Ollama 服務正在運行
- 首次使用前請確認已下載所需的 AI 模型
- 模型回應速度取決於您的硬體配置
- 翻譯功能目前設定為繁體中文到英文

## 🎯 使用建議與限制

### ⚠️ 內容準確性提醒

> **此範例只是一個小型示範專案，請務必查證大語言模型的輸出內容是否有誤！**

大語言模型可能會產生不準確或過時的資訊。建議您：
- ✅ 將輸出內容作為**參考**，而非絕對事實
- ✅ 對重要資訊進行**交叉驗證**
- ✅ 在專業領域應用時，務必**人工審核**

### 🔧 進階應用方向

如果您想將此專案應用於專業領域，建議：

**採用 RAG（檢索增強生成）技術** 📖
- 整合專業知識庫或文件資料庫
- 讓模型基於可靠來源回答問題
- 大幅提升回答的準確性和專業性
- 可追溯資訊來源

範例應用場景：
- 🏥 醫療諮詢系統（整合醫學文獻）
- ⚖️ 法律諮詢助手（整合法規條文）
- 🏢 企業知識管理（整合內部文件）
- 📚 教育輔助工具（整合教材內容）

## 💰 本地運行的優勢

### 🆚 相比 ChatGPT、Gemini、Claude

本專案**完全在本地端運行**，具有以下獨特優勢：

| 特點 | 本專案 (Ollama) | ChatGPT/Gemini/Claude |
|-----|----------------|----------------------|
| 💵 費用 | **完全免費** | 需付費訂閱或按量計費 |
| 🔢 使用次數 | **無限制** | 有每日/每月額度限制 |
| 🔒 隱私保護 | **資料不上傳** | 資料傳送至雲端 |
| 🌐 網路需求 | 僅初次下載模型 | 必須持續連線 |
| ⚙️ 客製化 | **完全可控** | 受平台限制 |
| 📊 資料安全 | **100% 本地** | 需信任第三方 |

### ✨ 主要優勢

1. **💸 零成本運行**
   - 無需訂閱費用
   - 無需 API 金鑰
   - 無需擔心額度用完

2. **🔓 真正的無限使用**
   - 想問多少次就問多少次
   - 沒有每日訊息限制
   - 沒有 Token 計費

3. **🔐 隱私與安全**
   - 所有對話都在本地處理
   - 敏感資訊不會上傳雲端
   - 適合處理機密或個人資料

4. **🎮 完全掌控**
   - 可以自由切換模型
   - 可以調整系統提示
   - 可以修改程式邏輯

## 🔧 疑難排解

### 連接 Ollama 失敗

確認 Ollama 服務是否正在運行：

```bash
ollama list
ollama serve
```

### 模型未找到

重新下載所需模型：

```bash
ollama pull llama3.1:latest
ollama pull translategemma:4b
```

## 🤝 貢獻

歡迎提出問題和改進建議！

---

<div align="center">

**🌟 如果這個專案對您有幫助，歡迎給個 Star！🌟**

Made with ❤️ by AJI0417

</div>
